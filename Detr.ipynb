{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7xOqzgC6swp"
      },
      "outputs": [],
      "source": [
        " !pip install -U diffusers\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from huggingface_hub import notebook_login\n",
        "# Log in to your Hugging Face account\n",
        "notebook_login()\n",
        "\n",
        "# Token :  use your huggingface access token"
      ],
      "metadata": {
        "id": "rGEHz-TQ7hN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write a gradio app for the above model impementation\n",
        "import gradio as gr\n",
        "from PIL import Image\n",
        "import requests\n",
        "import torch\n",
        "from transformers import DetrImageProcessor, DetrForObjectDetection"
      ],
      "metadata": {
        "id": "cH2oultx7duh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# you can specify the revision tag if you don't want the timm dependency\n",
        "processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\", revision=\"no_timm\")\n",
        "model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\", revision=\"no_timm\")"
      ],
      "metadata": {
        "id": "Or3X8nrmAF7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(image):\n",
        "    inputs = processor(images=image, return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    # Convert outputs (bounding boxes and class logits) to COCO API\n",
        "    # Let's only keep detections with score > 0.9\n",
        "    target_sizes = torch.tensor([image.size[::-1]])\n",
        "    results = processor.post_process_object_detection(\n",
        "        outputs, target_sizes=target_sizes, threshold=0.9\n",
        "    )[0]\n",
        "\n",
        "    # Create a list of detected objects\n",
        "    detected_objects = []\n",
        "    for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
        "        box = [round(i, 2) for i in box.tolist()]\n",
        "        detected_objects.append(\n",
        "            f\"Detected {model.config.id2label[label.item()]} with confidence \"\n",
        "            f\"{round(score.item(), 3)} at location {box}\"\n",
        "        )\n",
        "\n",
        "    return \"\\n\".join(detected_objects)\n"
      ],
      "metadata": {
        "id": "YLlBxoMIAKCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo = gr.Interface(\n",
        "   fn=inference,\n",
        "   inputs=gr.Image(type=\"pil\"),\n",
        "   outputs=gr.Textbox(),\n",
        ")\n",
        "\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "lz6eiGeyA0Zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# prompt: rather than just printing the results i want the boxes to be drawn on the picture with labels to show what object it is\n",
        "\n",
        "\n",
        "import torch\n",
        "from diffusers import FluxPipeline\n",
        "from huggingface_hub import notebook_login\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
        "from PIL import ImageDraw, ImageFont\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "\n",
        "# you can specify the revision tag if you don't want the timm dependency\n",
        "processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\", revision=\"no_timm\")\n",
        "model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\", revision=\"no_timm\")\n",
        "\n",
        "\n",
        "def inference(image):\n",
        " inputs = processor(images=image, return_tensors=\"pt\")\n",
        " outputs = model(**inputs)\n",
        "\n",
        "\n",
        " # convert outputs (bounding boxes and class logits) to COCO API\n",
        " # let's only keep detections with score > 0.9\n",
        " target_sizes = torch.tensor([image.size[::-1]])\n",
        " results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.9)[0]\n",
        "\n",
        "\n",
        " # Draw bounding boxes and labels on the image\n",
        " draw = ImageDraw.Draw(image)\n",
        " font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf\", 15)  # You might need to adjust the font path\n",
        "\n",
        "\n",
        " for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
        "   box = [round(i, 2) for i in box.tolist()]\n",
        "   draw.rectangle(box, outline=\"red\", width=2)\n",
        "   label_text = f\"{model.config.id2label[label.item()]}\"\n",
        "   draw.text((box[0], box[1]), label_text, fill=\"red\", font=font)\n",
        "\n",
        "\n",
        " return image\n",
        "\n",
        "\n",
        "demo = gr.Interface(\n",
        "   fn=inference,\n",
        "   inputs=gr.Image(type=\"pil\"),\n",
        "   outputs=gr.Image(type=\"pil\"),\n",
        ")\n",
        "\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "qId03fiy6wqd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}